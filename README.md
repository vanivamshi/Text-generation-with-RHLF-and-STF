# Text-generation-with-RHLF-and-STF
Simple text generation using GPT-2. Uses,
1) STF - Fine-tune the pretrained model using a specific dataset with input-output pairs
2) RHLF - Fine-tune the SFT model by optimizing it based on human feedback, using reinforcement learning
3) Time taken
4) Memory usage
5) Number of tokens generated
6) BLEU score
7) ROUGE score
8) A/B testing
9) Temperature
10) Top-k Sampling
11) Repetition Penalty
12) Length Penalty
